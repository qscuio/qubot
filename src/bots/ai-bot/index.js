const BotInstance = require("../../core/BotInstance");
const { DEFAULT_PROVIDER, getProvider, listProviders, fetchModels, callAI } = require("../../providers");

/**
 * AiBot - Multi-provider AI chat bot.
 * Supports: Groq, Gemini, OpenAI, Claude, NVIDIA
 */
class AiBot extends BotInstance {
    constructor(token, config) {
        super("ai-bot", token);
        this.config = config;

        // User settings: { [userId]: { provider, model } }
        this.userSettings = new Map();
        // Cached models: { [provider]: models[] }
        this.cachedModels = new Map();
    }

    async setup() {
        if (!this.isEnabled()) {
            this.logger.warn("AI Bot token not configured.");
            return;
        }

        // Register commands
        this.command("ai", "AI å¯¹è¯", (ctx) => this._handleAi(ctx));
        this.command("providers", "é€‰æ‹© AI æä¾›å•†", (ctx) => this._handleProviders(ctx));
        this.command("models", "é€‰æ‹©æ¨¡å‹", (ctx) => this._handleModels(ctx));
        this.command("help", "å¸®åŠ©", (ctx) => this._handleHelp(ctx));

        // Handle callback queries
        this.action(/^provider:(.+)$/, (ctx) => this._handleProviderSelect(ctx));
        this.action(/^model:(.+)$/, (ctx) => this._handleModelSelect(ctx));

        // Handle plain text messages
        this.onText((ctx) => this._handleText(ctx));

        this.logger.info("AiBot commands registered: /ai, /providers, /models");
    }

    _getSettings(userId) {
        if (!this.userSettings.has(userId)) {
            this.userSettings.set(userId, {
                provider: DEFAULT_PROVIDER,
                model: getProvider(DEFAULT_PROVIDER)?.defaultModel || "",
            });
        }
        return this.userSettings.get(userId);
    }

    async _handleAi(ctx) {
        const userId = ctx.from?.id;
        const prompt = (ctx.message.text || "").replace("/ai", "").trim();

        if (!prompt) {
            return ctx.reply("ğŸ“Œ ç”¨æ³•: /ai <é—®é¢˜>\nä¾‹å¦‚: /ai ä»€ä¹ˆæ˜¯é‡å­è®¡ç®—?");
        }

        await this._processAI(ctx, userId, prompt);
    }

    async _handleText(ctx) {
        const text = ctx.message.text || "";
        if (text.startsWith("/")) return;

        // In group chats, require bot mention or reply
        if (ctx.chat.type !== "private") {
            const botMentioned = text.includes("@" + ctx.botInfo?.username);
            const isReply = ctx.message.reply_to_message?.from?.id === ctx.botInfo?.id;
            if (!botMentioned && !isReply) return;
        }

        const userId = ctx.from?.id;
        await this._processAI(ctx, userId, text);
    }

    async _processAI(ctx, userId, prompt) {
        const settings = this._getSettings(userId);
        const provider = getProvider(settings.provider);

        if (!provider.isConfigured(this.config)) {
            return ctx.reply(
                `âŒ ${provider.name} API Key æœªé…ç½®ã€‚\n\n` +
                `ä½¿ç”¨ /providers åˆ‡æ¢åˆ°å·²é…ç½®çš„æä¾›å•†ã€‚`
            );
        }

        await ctx.sendChatAction("typing");

        const statusMsg = await ctx.reply(
            `ğŸ¤” æ€è€ƒä¸­...\n\nğŸ“¡ ${provider.name}: ${settings.model}`
        );

        const typingInterval = setInterval(() => {
            ctx.sendChatAction("typing").catch(() => { });
        }, 4000);

        try {
            const response = await callAI(
                settings.provider,
                this.config,
                prompt,
                settings.model,
                [],
                ""
            );

            clearInterval(typingInterval);

            await ctx.telegram.editMessageText(
                ctx.chat.id,
                statusMsg.message_id,
                null,
                `âœ… å®Œæˆ!`
            );

            if (response.thinking) {
                const thinking = response.thinking.substring(0, 800);
                await ctx.reply(
                    `ğŸ’­ *æ¨ç†è¿‡ç¨‹:*\n\n_${this._escapeMarkdown(thinking)}${response.thinking.length > 800 ? "..." : ""}_`,
                    { parse_mode: "Markdown" }
                );
            }

            if (response.content) {
                await this._sendLongMessage(ctx, `ğŸ’¬ *${provider.name}:*\n\n${response.content}`);
            } else {
                await ctx.reply("âš ï¸ AI æ²¡æœ‰è¿”å›å“åº”ï¼Œè¯·å°è¯•å…¶ä»–æ¨¡å‹ã€‚");
            }
        } catch (err) {
            clearInterval(typingInterval);
            this.logger.error("AI request failed", err);
            await ctx.reply(`âŒ è¯·æ±‚å¤±è´¥: ${err.message}\n\nä½¿ç”¨ /providers åˆ‡æ¢æä¾›å•†ã€‚`);
        }
    }

    async _handleProviders(ctx) {
        const userId = ctx.from?.id;
        const settings = this._getSettings(userId);

        const buttons = listProviders().map((p) => [{
            text: `${p.key === settings.provider ? "âœ… " : ""}${p.name}`,
            callback_data: `provider:${p.key}`,
        }]);

        await ctx.reply("ğŸ”Œ é€‰æ‹© AI æä¾›å•†:", {
            reply_markup: { inline_keyboard: buttons },
        });
    }

    async _handleProviderSelect(ctx) {
        const userId = ctx.from?.id;
        const providerKey = ctx.match[1];
        const provider = getProvider(providerKey);

        if (!provider) {
            return ctx.answerCbQuery("âŒ æœªçŸ¥æä¾›å•†");
        }

        const settings = this._getSettings(userId);
        settings.provider = providerKey;
        settings.model = provider.defaultModel;

        await ctx.answerCbQuery(`âœ… å·²åˆ‡æ¢åˆ° ${provider.name}`);
        await ctx.editMessageText(
            `âœ… å·²é€‰æ‹©: *${provider.name}*\n\nğŸ“ é»˜è®¤æ¨¡å‹: \`${provider.defaultModel}\`\n\nä½¿ç”¨ /models åˆ‡æ¢æ¨¡å‹`,
            { parse_mode: "Markdown" }
        );
    }

    async _handleModels(ctx) {
        const userId = ctx.from?.id;
        const settings = this._getSettings(userId);
        const provider = getProvider(settings.provider);

        await ctx.reply("â³ æ­£åœ¨è·å–æ¨¡å‹åˆ—è¡¨...");

        // Fetch models (with caching)
        let models;
        if (this.cachedModels.has(settings.provider)) {
            models = this.cachedModels.get(settings.provider);
        } else {
            models = await fetchModels(settings.provider, this.config);
            this.cachedModels.set(settings.provider, models);
        }

        if (models.length === 0) {
            return ctx.reply("âŒ å½“å‰æä¾›å•†æ²¡æœ‰å¯ç”¨æ¨¡å‹");
        }

        // Limit to 10 models for UI
        const displayModels = models.slice(0, 10);

        const buttons = displayModels.map((m) => [{
            text: `${m.id === settings.model ? "âœ… " : ""}${m.name}`,
            callback_data: `model:${m.id}`,
        }]);

        await ctx.reply(`ğŸ“ é€‰æ‹©æ¨¡å‹ (${provider.name}):`, {
            reply_markup: { inline_keyboard: buttons },
        });
    }

    async _handleModelSelect(ctx) {
        const userId = ctx.from?.id;
        const modelId = ctx.match[1];
        const settings = this._getSettings(userId);

        settings.model = modelId;

        await ctx.answerCbQuery(`âœ… æ¨¡å‹å·²åˆ‡æ¢`);
        await ctx.editMessageText(`âœ… å·²é€‰æ‹©æ¨¡å‹: \`${modelId}\``, { parse_mode: "Markdown" });
    }

    async _handleHelp(ctx) {
        await ctx.reply(
            "ğŸ§  *AI Bot å¸®åŠ©*\n\n" +
            "/ai <é—®é¢˜> - å‘ AI æé—®\n" +
            "/providers - é€‰æ‹© AI æä¾›å•†\n" +
            "/models - é€‰æ‹©æ¨¡å‹\n\n" +
            "*æ”¯æŒçš„æä¾›å•†:*\n" +
            "- Groq (é»˜è®¤)\n" +
            "- Google Gemini\n" +
            "- OpenAI (GPT-4)\n" +
            "- Anthropic Claude\n" +
            "- NVIDIA NIM",
            { parse_mode: "Markdown" }
        );
    }

    async _sendLongMessage(ctx, text, maxLength = 4000) {
        if (text.length <= maxLength) {
            return ctx.reply(text, { parse_mode: "Markdown" });
        }

        const chunks = [];
        let current = "";

        for (const line of text.split("\n")) {
            if (current.length + line.length > maxLength) {
                if (current) chunks.push(current);
                current = line;
            } else {
                current += (current ? "\n" : "") + line;
            }
        }
        if (current) chunks.push(current);

        for (const chunk of chunks) {
            await ctx.reply(chunk, { parse_mode: "Markdown" });
        }
    }

    _escapeMarkdown(text) {
        if (!text) return "";
        return text.replace(/[_*[\]()~`>#+=|{}.!-]/g, "\\$&");
    }
}

module.exports = AiBot;
