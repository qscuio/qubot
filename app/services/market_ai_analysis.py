"""
Aè‚¡å¸‚åœºAIåˆ†ææœåŠ¡ (A-Share Market AI Analysis Service)

Using ported Core Algorithms from daily_stock_analysis:
- MarketAnalyzerLogic: For indices and sector overview.
- StockTrendAnalyzer: For deep dive technical analysis on top stocks.

Features:
- Robust data fetching with retry.
- Deterministic technical analysis (MA, Bias, Trend).
- Professional AI reporting.
"""

import asyncio
import logging
import random
import time
from datetime import datetime, date, timedelta
from typing import Dict, List, Optional

import pandas as pd
import akshare as ak

from app.core.config import settings
from app.core.bot import telegram_service
from app.core.timezone import china_now, china_today
from app.services.ai import ai_service
from app.services.stock_trend_analyzer import StockTrendAnalyzer, TrendAnalysisResult
from app.services.market_analyzer import MarketAnalyzerLogic, MarketOverview

logger = logging.getLogger(__name__)


class MarketAIAnalysisService:
    """Market AI Analysis Service with Robust Fetching & Core Algorithms"""
    
    def __init__(self):
        self.is_running = False
        self._scheduler_task = None
        self._triggered_today = set()
        
        # Analyzers
        self.trend_analyzer = StockTrendAnalyzer()
        self.market_analyzer = MarketAnalyzerLogic()
        
    async def start(self):
        """Start the service"""
        if self.is_running:
            return
            
        report_target = settings.REPORT_TARGET_GROUP or settings.REPORT_TARGET_CHANNEL
        if not report_target:
            logger.warning("REPORT_TARGET_GROUP/CHANNEL not configured, analysis service disabled")
            return
            
        self.is_running = True
        self._scheduler_task = asyncio.create_task(self._scheduler_loop())
        logger.info("âœ… Market AI Analysis Service started (with Core Algorithms)")

    async def stop(self):
        """Stop the service"""
        self.is_running = False
        if self._scheduler_task:
            self._scheduler_task.cancel()
            try:
                await self._scheduler_task
            except asyncio.CancelledError:
                pass
        logger.info("Market AI Analysis Service stopped")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Data Fetching (Robust)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def _fetch_with_retry(self, func, *args, retries=3, delay=2, **kwargs):
        """Execute akshare function with retry logic"""
        for i in range(retries):
            try:
                # Run in thread pool to avoid blocking async loop
                return await asyncio.to_thread(func, *args, **kwargs)
            except Exception as e:
                if i == retries - 1:
                    logger.error(f"Fetch failed after {retries} attempts: {e}")
                    return None
                logger.warning(f"Fetch attempt {i+1} failed: {e}, retrying...")
                await asyncio.sleep(delay * (i + 1))
        return None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Market Overview
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def get_market_overview_data(self) -> Optional[MarketOverview]:
        """Fetch and aggregate market overview data"""
        try:
            # 1. Major Indices (Keep online fetch as per plan - not in DB)
            indices_df = await self._fetch_with_retry(ak.stock_zh_index_spot_sina)
            
            # 2. Sectors (Keep online fetch as per plan - not in DB)
            sector_df = await self._fetch_with_retry(ak.stock_board_industry_name_em)
            
            # 3. Market Stats (Use Local DB)
            today = china_today()
            from app.services.stock_history import stock_history_service
            market_stats = await stock_history_service.get_daily_market_stats(today)
            
            # Create partial market_df for MarketAnalyzer if stats available
            # MarketAnalyzer expects a generic structure. We might need to adjust it 
            # or manually create the MarketOverview object.
            # Let's bypass MarketAnalyzer.process_market_data partially/completely or mock the DF?
            # Actually, constructing a partial DataFrame from stats is hard because process_market_data calculates counts itself.
            # Best approach: Use MarketAnalyzer for Indices/Sectors, but inject our DB stats.
            
            # Let's see MarketAnalyzerLogic.process_market_data signature...
            # It takes (indices_df, market_df, sector_df).
            # If we pass None for market_df, it returns None?
            # We should probably modify process_market_data to accept pre-calculated stats 
            # OR manually build MarketOverview here. Manually building is safer/cleaner here.
            
            # Helper to parse indices
            indices = []
            if indices_df is not None and not indices_df.empty:
                # Same logic as MarketAnalyzer
                main_indices = ['ä¸Šè¯æŒ‡æ•°', 'æ·±è¯æˆæŒ‡', 'åˆ›ä¸šæ¿æŒ‡', 'ç§‘åˆ›50']
                for _, row in indices_df.iterrows():
                    name = row['åç§°']
                    if name in main_indices:
                        indices.append(type('obj', (object,), {
                            'name': name,
                            'change_pct': float(row['æ¶¨è·Œå¹…'])
                        }))

            # Helper to parse sectors
            top_sectors = []
            bottom_sectors = []
            if sector_df is not None and not sector_df.empty:
                sector_df['æ¶¨è·Œå¹…'] = pd.to_numeric(sector_df['æ¶¨è·Œå¹…'], errors='coerce')
                df_sorted = sector_df.sort_values('æ¶¨è·Œå¹…', ascending=False)
                for _, row in df_sorted.head(5).iterrows():
                    top_sectors.append({'name': row['æ¿å—åç§°'], 'change': row['æ¶¨è·Œå¹…']})
                for _, row in df_sorted.tail(5).iterrows():
                    bottom_sectors.append({'name': row['æ¿å—åç§°'], 'change': row['æ¶¨è·Œå¹…']})
            
            if not market_stats:
                # If DB has no data for today (yet), maybe try fallback?
                # User asked to replace online fetch. We return None if not ready.
                return None
                
            return MarketOverview(
                indices=indices,
                top_sectors=top_sectors,
                bottom_sectors=bottom_sectors,
                up_count=market_stats['up_count'],
                down_count=market_stats['down_count'],
                flat_count=market_stats['flat_count'],
                total_amount=market_stats['total_turnover'] / 100000000, # Convert to Hundred Millions
                total_volume=market_stats['total_volume']
            )
            
        except Exception as e:
            logger.error(f"Failed to get market overview: {e}")
            return None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Deep Dive Analysis (Top Stock)
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def analyze_stock_deep_dive(self, code: str, name: str) -> Optional[TrendAnalysisResult]:
        """Perform deep technical analysis on a single stock using Local DB"""
        try:
            from app.services.stock_history import stock_history_service
            df = await stock_history_service.get_stock_df(code, days=200)
            
            if df is None or df.empty:
                return None
            
            return self.trend_analyzer.analyze(df, code)
            
        except Exception as e:
            logger.error(f"Deep dive failed for {code}: {e}")
            return None

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Report Generation
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

    async def generate_daily_report(self, progress_callback=None) -> str:
        """
        Generate the comprehensive AI report
        
        Args:
            progress_callback: Optional async function(current, total, message) used to report progress
        """
        async def _report(current, total, msg):
            if progress_callback:
                try:
                    await progress_callback(current, total, msg)
                except Exception:
                    pass

        # 1. Get Market Overview (now uses DB for stats)
        await _report(10, 100, "æ­£åœ¨é‡‡é›†å¸‚åœºæ¦‚å†µæ•°æ® (Local DB + API)...")
        overview = await self.get_market_overview_data()
        if not overview:
            # Check reasons? Maybe DB not updated?
            return "âŒ æ— æ³•è·å–ä»Šæ—¥å¸‚åœºæ•°æ®ã€‚å¯èƒ½æœ¬åœ°æ•°æ®åº“å°šæœªåŒæ­¥ï¼Œè¯·ç¨åå†è¯• (15:30åæ•°æ®åŒæ­¥å®Œæˆ)ã€‚"
            
        overview_text = self.market_analyzer.format_market_overview(overview)
        
        # 2. Identify Top Stock (from DB)
        await _report(30, 100, "æ­£åœ¨ç­›é€‰ä»Šæ—¥å…³æ³¨æ˜Ÿæ ‡è‚¡...")
        top_stock = None
        trend_result = None
        
        try:
            from app.services.stock_history import stock_history_service
            today = china_today()
            top_gainers = await stock_history_service.get_top_gainers_db(today, limit=5)
            
            if top_gainers:
                row = top_gainers[0]
                code = row['code']
                name = row['name'] or code
                change = row['change_pct']
                
                await _report(50, 100, f"æ­£åœ¨å¯¹ {name}({code}) è¿›è¡Œæ·±åº¦æŠ€æœ¯å¤ç›˜...")
                trend_result = await self.analyze_stock_deep_dive(code, name)
                if trend_result:
                    top_stock = {'code': code, 'name': name, 'change': change}
        except Exception as e:
            logger.error(f"Failed to get top stock from DB: {e}")

        # 3. Build AI Prompt
        prompt = self._build_ai_prompt(overview, top_stock, trend_result)
        
        # 4. Generate AI Content
        await _report(70, 100, "AIæ­£åœ¨æ·±åº¦æ€è€ƒä¸æ’°å†™æŠ¥å‘Š (çº¦éœ€15ç§’)...")
        try:
            result = await ai_service.analyze(prompt)
            ai_content = result.get("content", "âš ï¸ AIæœªè¿”å›æœ‰æ•ˆå†…å®¹")
        except Exception as e:
            ai_content = f"âš ï¸ AIåˆ†ææš‚æ—¶ä¸å¯ç”¨ ({e})\n\nè¯·å‚è€ƒä¸Šæ–¹å®¢è§‚æ•°æ®ã€‚"
            
        await _report(100, 100, "æŠ¥å‘Šç”Ÿæˆå®Œæˆ")

        # 5. Assemble Final Report
        report = [
            overview_text,
            "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”",
            "ğŸ¤– <b>AI æ·±åº¦å¤ç›˜</b>",
            "",
            ai_content
        ]
        
        return "\n".join(report)

    def _build_ai_prompt(self, overview: MarketOverview, top_stock: dict, trend: Optional[TrendAnalysisResult]) -> str:
        """Build the System Prompt for AI (Ported from daily_stock_analysis)"""
        
        # Indices Stats
        indices_str = ", ".join([f"{i.name}{i.change_pct:+.2f}%" for i in overview.indices])
        
        # Sectors
        sectors_up = ", ".join([f"{s['name']}" for s in overview.top_sectors[:3]])
        sectors_down = ", ".join([f"{s['name']}" for s in overview.bottom_sectors[:3]])
        
        # Deep Dive Data
        deep_dive_text = "æš‚æ— å…·ä½“ä¸ªè‚¡æ·±åº¦åˆ†ææ•°æ®"
        if trend:
            deep_dive_text = f"""
ã€ä»Šæ—¥å…³æ³¨æ˜Ÿæ ‡è‚¡ã€‘ï¼š{top_stock['name']} ({top_stock['code']})
- æ¶¨è·Œå¹…ï¼š{top_stock['change']}%
- è¶‹åŠ¿çŠ¶æ€ï¼š{trend.trend_status.value} (å¼ºåº¦ {trend.trend_strength})
- å‡çº¿å½¢æ€ï¼š{trend.ma_alignment}
- MA5ä¹–ç¦»ç‡ï¼š{trend.bias_ma5:.2f}% ({'âš ï¸åé«˜' if trend.bias_ma5 > 5 else 'âœ…å®‰å…¨'})
- é‡èƒ½çŠ¶æ€ï¼š{trend.volume_status.value}
- ç³»ç»Ÿè¯„åˆ†ï¼š{trend.signal_score}åˆ† ({trend.buy_signal.value})
- ä¿¡å·ç†ç”±ï¼š{', '.join(trend.signal_reasons)}
- é£é™©æç¤ºï¼š{', '.join(trend.risk_factors)}
"""

        prompt = f"""ä½ æ˜¯ä¸€ä½ä¸“æ³¨äºè¶‹åŠ¿äº¤æ˜“çš„ A è‚¡æŠ•èµ„åˆ†æå¸ˆã€‚è¯·æ ¹æ®ä»¥ä¸‹å®¢è§‚æ•°æ®ï¼Œç”Ÿæˆä¸€ä»½ä¸“ä¸šçš„ã€å†³ç­–ä»ªè¡¨ç›˜ã€‘é£æ ¼çš„å¸‚åœºå¤ç›˜æŠ¥å‘Šã€‚

## æ ¸å¿ƒäº¤æ˜“ç†å¿µï¼ˆå¿…é¡»ä¸¥æ ¼éµå®ˆï¼‰

### 1. ä¸¥è¿›ç­–ç•¥ï¼ˆä¸è¿½é«˜ï¼‰
- **ç»å¯¹ä¸è¿½é«˜**ï¼šå½“è‚¡ä»·åç¦» MA5 è¶…è¿‡ 5% æ—¶ï¼Œåšå†³ä¸ä¹°å…¥
- **ä¹–ç¦»ç‡å…¬å¼**ï¼š(ç°ä»· - MA5) / MA5 Ã— 100%
- ä¹–ç¦»ç‡ < 2%ï¼šæœ€ä½³ä¹°ç‚¹åŒºé—´
- ä¹–ç¦»ç‡ 2-5%ï¼šå¯å°ä»“ä»‹å…¥
- ä¹–ç¦»ç‡ > 5%ï¼šä¸¥ç¦è¿½é«˜ï¼ç›´æ¥åˆ¤å®šä¸º"è§‚æœ›"

### 2. è¶‹åŠ¿äº¤æ˜“ï¼ˆé¡ºåŠ¿è€Œä¸ºï¼‰
- **å¤šå¤´æ’åˆ—å¿…é¡»æ¡ä»¶**ï¼šMA5 > MA10 > MA20
- åªåšå¤šå¤´æ’åˆ—çš„è‚¡ç¥¨ï¼Œç©ºå¤´æ’åˆ—åšå†³ä¸ç¢°
- å‡çº¿å‘æ•£ä¸Šè¡Œä¼˜äºå‡çº¿ç²˜åˆ
- è¶‹åŠ¿å¼ºåº¦åˆ¤æ–­ï¼šçœ‹å‡çº¿é—´è·æ˜¯å¦åœ¨æ‰©å¤§

### 3. æ•ˆç‡ä¼˜å…ˆï¼ˆç­¹ç ç»“æ„ï¼‰
- å…³æ³¨ç­¹ç é›†ä¸­åº¦ä¸è·åˆ©æ¯”ä¾‹
- ç¼©é‡å›è°ƒæ˜¯æ´—ç›˜ï¼Œæ”¾é‡ä¸‹è·Œè¦æ³¨æ„é£é™©

### 4. é£é™©æ’æŸ¥é‡ç‚¹
- å…³æ³¨å‡æŒå…¬å‘Šã€ä¸šç»©é¢„äºã€ç›‘ç®¡å¤„ç½šç­‰é‡å¤§åˆ©ç©º
- è·Œç ´ MA20 æ—¶éœ€è°¨æ…è§‚æœ›

---

## ä»Šæ—¥å¸‚åœºæ•°æ®
- æŒ‡æ•°è¡¨ç°ï¼š{indices_str}
- æ¶¨è·Œå®¶æ•°ï¼šæ¶¨{overview.up_count}/è·Œ{overview.down_count}
- æˆäº¤é‡‘é¢ï¼š{overview.total_amount:.0f}äº¿
- é¢†æ¶¨æ¿å—ï¼š{sectors_up}
- é¢†è·Œæ¿å—ï¼š{sectors_down}

{deep_dive_text}

---

## ä»»åŠ¡è¦æ±‚
è¯·åŸºäºä»¥ä¸Šæ•°æ®å’Œ**æ ¸å¿ƒäº¤æ˜“ç†å¿µ**ï¼Œç”Ÿæˆä¸€ä»½ç®€ç»ƒã€çŠ€åˆ©çš„æ–‡æœ¬æŠ¥å‘Šï¼ˆç›´æ¥è¾“å‡ºæŠ¥å‘Šå†…å®¹ï¼Œæ— éœ€Markdownæ ‡é¢˜ï¼‰ï¼š

1. **å¸‚åœºå®šè°ƒ**ï¼šç”¨ä¸€å¥è¯æ¦‚æ‹¬ä»Šæ—¥è¡Œæƒ…ï¼ˆå¦‚"æ”¾é‡æ™®æ¶¨"ã€"ç¼©é‡åˆ†åŒ–"ã€"æƒ…ç»ªä¿®å¤"ç­‰ï¼‰ï¼Œå¹¶ç‚¹è¯„å¸‚åœºèµšé’±æ•ˆåº”ã€‚
2. **çƒ­ç‚¹å¤ç›˜**ï¼šç®€æé¢†æ¶¨æ¿å—çš„é©±åŠ¨é€»è¾‘ï¼ŒæŒ‡å‡ºæ˜¯æ¸¸èµ„ç‚’ä½œè¿˜æ˜¯æœºæ„æŠ±å›¢ã€‚
3. **æ“ä½œå»ºè®®**ï¼šè¿™æ˜¯ä¸€ä»½ç»™ç”¨æˆ·çš„å®æ“æŒ‡å—ã€‚
   - ä»“ä½å»ºè®®ï¼ˆç©ºä»“/åŠä»“/æ»¡ä»“ï¼‰ã€‚
   - å…·ä½“æ–¹å‘ï¼ˆæ˜¯è¿›æ”»çƒ­é—¨ï¼Œè¿˜æ˜¯é˜²å®ˆä½å¸ï¼‰ã€‚
4. **æ˜Ÿæ ‡è‚¡æ·±è¯„**ï¼ˆå¦‚æœæœ‰ï¼‰ï¼š
   - ä¸¥æ ¼æ ¹æ®ã€æ ¸å¿ƒäº¤æ˜“ç†å¿µã€‘ç‚¹è¯„è¯¥è‚¡ã€‚
   - é‡ç‚¹æ£€æŸ¥ï¼šä¹–ç¦»ç‡æ˜¯å¦è¿‡é«˜ï¼Ÿæ˜¯å¦å¤šå¤´æ’åˆ—ï¼Ÿé‡èƒ½æ˜¯å¦å¥åº·ï¼Ÿ
   - **å¿…é¡»ç»™å‡ºæ˜ç¡®ç»“è®º**ï¼šæ˜¯"æœºä¼š"è¿˜æ˜¯"é£é™©"ï¼Ÿ

**é£æ ¼è¦æ±‚**ï¼š
- è¯­è¨€é£æ ¼ï¼šä¸“ä¸šã€å®¢è§‚ã€çŠ€åˆ©ï¼Œæ‹’ç»æ¨¡æ£±ä¸¤å¯çš„åºŸè¯ã€‚
- é£é™©æ§åˆ¶ï¼šæŠŠé£é™©æç¤ºæ”¾åœ¨é¦–ä½ï¼Œç‰¹åˆ«æ˜¯å¯¹äºé«˜ä½è‚¡ã€‚
- å­—æ•°æ§åˆ¶ï¼š400å­—å·¦å³ã€‚
"""
        return prompt

    async def send_daily_analysis(self):
        """Send the analysis to the target channel"""
        report_target = settings.REPORT_TARGET_GROUP or settings.REPORT_TARGET_CHANNEL
        if not report_target:
            return

        logger.info("Generating Daily Market AI Report...")
        report = await self.generate_daily_report()
        
        await telegram_service.send_message(
            report_target,
            report,
            parse_mode="html",
            link_preview=False
        )
        logger.info("âœ… Daily Report Sent.")

    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    # Scheduler Logic
    # â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€
    
    async def _scheduler_loop(self):
        """Daily Schedule Loop"""
        while self.is_running:
            try:
                now = china_now()
                # Schedule for 15:30 on weekdays
                if now.hour == 15 and now.minute == 30 and now.weekday() < 5:
                    date_str = now.strftime("%Y-%m-%d")
                    if date_str not in self._triggered_today:
                        self._triggered_today.add(date_str)
                        asyncio.create_task(self.send_daily_analysis())
                
                # Reset triggers at midnight
                if now.hour == 0 and now.minute == 0:
                    self._triggered_today.clear()
                    
            except Exception as e:
                logger.error(f"Scheduler error: {e}")
            
            await asyncio.sleep(60)

market_ai_analysis_service = MarketAIAnalysisService()
