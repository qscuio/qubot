"""
Module 1: Data Preprocessor (Non-LLM)

Annotates messages with features using regex patterns:
- Direction words (æ¶¨/è·Œ/å¤š/ç©º)
- Action words (ä¹°/å–/åŠ ä»“/å‡ä»“)
- Condition words (å¦‚æœ/åªè¦/ä¸ç ´)
- Hindsight markers (æœç„¶/æ—©å°±è¯´)
- Emotional expressions

Also builds the reply graph for citation tracking.
No LLM calls - all rule-based.
"""

import re
import hashlib
from collections import defaultdict
from datetime import datetime
from typing import List, Dict, Optional, Tuple, Any

from app.core.logger import Logger
from app.services.trader_influence.data_models import (
    AnnotatedMessage,
    MessageFeatures,
    DirectionType,
    ActionType,
)

logger = Logger("TraderPreprocessor")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Feature Detection Patterns (Rule-based, No LLM)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# Direction patterns - detect bullish/bearish sentiment
DIRECTION_PATTERNS = {
    DirectionType.BULLISH: [
        r'(?:çœ‹)?æ¶¨|åš?å¤š|ç‰›|å†²|æ‹‰å‡|èµ·é£|çªç ´|ä¸Šæ”»|åå¼¹|æ–°é«˜',
        r'åˆ©å¥½|åˆ©å¤š|åˆ©æ¶¨|å¼ºåŠ¿|æš´æ¶¨|å¤§æ¶¨',
        r'ä¹°ä¹°ä¹°|æŠ„åº•|æ»¡ä»“|åŠ ä»“',
        r'long|bullish|up|moon|pump',
    ],
    DirectionType.BEARISH: [
        r'(?:çœ‹)?è·Œ|åš?ç©º|ç†Š|å´©|ä¸‹è·Œ|è·³æ°´|ç ´ä½|ä¸‹æ€|å›è°ƒ',
        r'åˆ©ç©º|åˆ©è·Œ|å¼±åŠ¿|æš´è·Œ|å¤§è·Œ|è…°æ–©',
        r'å–å–å–|æ¸…ä»“|è·‘|æ’¤',
        r'short|bearish|down|crash|dump',
    ],
}

# Action patterns - detect trading actions
ACTION_PATTERNS = {
    ActionType.BUY: [
        r'ä¹°å…¥?|è¿›åœº?|å»ºä»“|å¼€å¤š|åšå¤š|æŠ„åº•',
        r'buy|long|enter|open',
    ],
    ActionType.SELL: [
        r'å–å‡º?|å‡ºåœº?|æ¸…ä»“|å¹³ä»“|æ­¢ç›ˆ|æ­¢æŸ',
        r'sell|close|exit|take profit|stop loss',
    ],
    ActionType.ADD: [
        r'åŠ ä»“|è¡¥ä»“|åŠ [å¤šç©º]|è¿½[å¤šç©º]',
        r'add|double down',
    ],
    ActionType.REDUCE: [
        r'å‡ä»“|å‡[å¤šç©º]|éƒ¨åˆ†å¹³',
        r'reduce|scale out',
    ],
}

# Condition patterns - detect conditional statements (forward-looking)
CONDITION_PATTERNS = [
    r'å¦‚æœ|åªè¦|é™¤é|ä¸€æ—¦|ç­‰åˆ°|è¦æ˜¯',
    r'(?:ä¸)?ç ´[ä½\d]|ç«™ç¨³|çªç ´.{0,5}å°±|è·Œç ´.{0,5}å°±',
    r'åˆ°äº†?[å°±å†]|è¾¾åˆ°.{0,5}å°±',
    r'if|unless|once|when|provided',
]

# Hindsight patterns - detect post-hoc statements (should be penalized)
HINDSIGHT_PATTERNS = [
    r'æœç„¶|æ—©å°±è¯´|ä¹‹å‰è¯´|æˆ‘è¯´çš„å§|éªŒè¯äº†|åº”éªŒ',
    r'çœ‹å§|æ€ä¹ˆæ ·|å¯¹å§|æ²¡é”™å§',
    r'told you|saw it coming|predicted|called it|i said',
]

# Emotional patterns - detect non-analytical emotional expressions
EMOTIONAL_PATTERNS = [
    r'[!ï¼]{2,}',                              # Multiple exclamations
    r'[?ï¼Ÿ]{2,}',                              # Multiple questions
    r'å§æ§½|æˆ‘[è‰è‰¹æ“é ]|å¤©å•Š|å®Œè›‹|ç‰›[é€¼æ‰¹]|å¤ª[ç‰›çŒ›]äº†',
    r'å“ˆå“ˆ{2,}|å‘µå‘µ{2,}|[å“­æ³£æµæ³ªğŸ˜­ğŸ˜¢]+',
    r'ğŸš€{2,}|ğŸ’°{2,}|ğŸ”¥{2,}',                   # Emoji spam
    r'aww+|wow+|omg|wtf|lmao|fuck',
]

# Compile all patterns for efficiency
def _compile_patterns(pattern_dict: Dict) -> Dict:
    """Compile regex patterns for a category dict."""
    return {
        key: [re.compile(p, re.IGNORECASE) for p in patterns]
        for key, patterns in pattern_dict.items()
    }

def _compile_list(patterns: List[str]) -> List:
    """Compile a list of patterns."""
    return [re.compile(p, re.IGNORECASE) for p in patterns]

COMPILED_DIRECTION = _compile_patterns(DIRECTION_PATTERNS)
COMPILED_ACTION = _compile_patterns(ACTION_PATTERNS)
COMPILED_CONDITION = _compile_list(CONDITION_PATTERNS)
COMPILED_HINDSIGHT = _compile_list(HINDSIGHT_PATTERNS)
COMPILED_EMOTIONAL = _compile_list(EMOTIONAL_PATTERNS)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Feature Detection Functions
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def detect_direction(text: str) -> Tuple[bool, Optional[DirectionType]]:
    """Detect if text contains direction words and which type."""
    for direction_type, patterns in COMPILED_DIRECTION.items():
        for pattern in patterns:
            if pattern.search(text):
                return True, direction_type
    return False, None


def detect_action(text: str) -> Tuple[bool, Optional[ActionType]]:
    """Detect if text contains action words and which type."""
    for action_type, patterns in COMPILED_ACTION.items():
        for pattern in patterns:
            if pattern.search(text):
                return True, action_type
    return False, None


def detect_condition(text: str) -> bool:
    """Detect if text contains conditional statements."""
    for pattern in COMPILED_CONDITION:
        if pattern.search(text):
            return True
    return False


def detect_hindsight(text: str) -> bool:
    """Detect if text is a hindsight/post-hoc statement."""
    for pattern in COMPILED_HINDSIGHT:
        if pattern.search(text):
            return True
    return False


def detect_emotional(text: str) -> bool:
    """Detect if text is primarily emotional expression."""
    for pattern in COMPILED_EMOTIONAL:
        if pattern.search(text):
            return True
    return False


def extract_features(text: str) -> MessageFeatures:
    """Extract all features from message text."""
    has_direction, direction_type = detect_direction(text)
    has_action, action_type = detect_action(text)
    has_condition = detect_condition(text)
    is_hindsight = detect_hindsight(text)
    is_emotional = detect_emotional(text)
    
    return MessageFeatures(
        has_direction=has_direction,
        has_action=has_action,
        has_condition=has_condition,
        is_hindsight=is_hindsight,
        is_emotional=is_emotional,
        direction_type=direction_type,
        action_type=action_type,
    )


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Preprocessor Class
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class Preprocessor:
    """
    Message preprocessor that annotates features and builds reply graph.
    
    All operations are rule-based, no LLM calls.
    """
    
    def process(
        self,
        messages: List[Dict[str, Any]],
    ) -> List[AnnotatedMessage]:
        """
        Process raw messages into annotated messages with features.
        
        Args:
            messages: Raw message dicts with message_id, user_id, user_name,
                     timestamp, text, reply_to
                     
        Returns:
            List of AnnotatedMessage with features and reply graph
        """
        if not messages:
            return []
        
        # Step 1: Normalize and sort by timestamp
        normalized = self._normalize_messages(messages)
        normalized.sort(key=lambda m: m.timestamp)
        
        # Step 2: Extract features for each message
        for msg in normalized:
            msg.features = extract_features(msg.text)
        
        # Step 3: Build reply graph
        self._build_reply_graph(normalized)
        
        logger.info(f"ğŸ“ Preprocessed {len(normalized)} messages")
        
        # Log feature stats
        forward_count = sum(1 for m in normalized if m.features.is_forward_looking)
        action_count = sum(1 for m in normalized if m.features.has_action)
        hindsight_count = sum(1 for m in normalized if m.features.is_hindsight)
        emotional_count = sum(1 for m in normalized if m.features.is_emotional)
        
        logger.debug(
            f"Features: forward_looking={forward_count}, "
            f"action={action_count}, hindsight={hindsight_count}, "
            f"emotional={emotional_count}"
        )
        
        return normalized
    
    def _normalize_messages(self, messages: List[Dict]) -> List[AnnotatedMessage]:
        """Convert raw message dicts to AnnotatedMessage objects."""
        result = []
        
        for msg in messages:
            try:
                # Extract required fields
                text = msg.get('text') or msg.get('message_text') or ''
                if not text.strip():
                    continue
                
                # Parse timestamp
                timestamp = msg.get('timestamp') or msg.get('created_at')
                if isinstance(timestamp, str):
                    try:
                        timestamp = datetime.fromisoformat(timestamp.replace('Z', '+00:00'))
                    except:
                        timestamp = datetime.now()
                elif not isinstance(timestamp, datetime):
                    timestamp = datetime.now()
                
                # Generate message ID if not present
                message_id = msg.get('message_id') or msg.get('id')
                if not message_id:
                    message_id = hashlib.md5(
                        f"{msg.get('user_id', '')}:{timestamp.isoformat()}:{text[:50]}".encode()
                    ).hexdigest()[:12]
                
                result.append(AnnotatedMessage(
                    message_id=str(message_id),
                    user_id=str(msg.get('user_id') or 'unknown'),
                    user_name=msg.get('user_name') or msg.get('sender_name') or 'Unknown',
                    timestamp=timestamp,
                    text=text,
                    reply_to=msg.get('reply_to'),
                ))
            except Exception as e:
                logger.debug(f"Failed to normalize message: {e}")
                continue
        
        return result
    
    def _build_reply_graph(self, messages: List[AnnotatedMessage]):
        """Build reply graph - track which messages reference which."""
        # Create message index
        msg_index = {m.message_id: m for m in messages}
        
        # Build reverse references
        for msg in messages:
            if msg.reply_to and msg.reply_to in msg_index:
                msg_index[msg.reply_to].referenced_by.append(msg.message_id)
    
    def get_user_messages(
        self,
        messages: List[AnnotatedMessage],
        user_id: str,
        only_forward_looking: bool = False,
    ) -> List[AnnotatedMessage]:
        """Get all messages from a specific user."""
        user_msgs = [m for m in messages if m.user_id == user_id]
        
        if only_forward_looking:
            user_msgs = [m for m in user_msgs if m.features.is_forward_looking]
        
        return user_msgs
    
    def get_forward_looking_messages(
        self,
        messages: List[AnnotatedMessage],
    ) -> List[AnnotatedMessage]:
        """Get all forward-looking (predictive) messages."""
        return [m for m in messages if m.features.is_forward_looking]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# Singleton Instance
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

preprocessor = Preprocessor()
